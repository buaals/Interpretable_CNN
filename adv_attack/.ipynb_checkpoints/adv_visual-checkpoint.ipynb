{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/jiali/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "This tutorial shows how to generate adversarial examples using FGSM\n",
    "and train a model using adversarial training with Keras.\n",
    "It is very similar to mnist_tutorial_tf.py, which does the same\n",
    "thing but without a dependence on keras.\n",
    "The original paper can be found at:\n",
    "https://arxiv.org/abs/1412.6572\n",
    "\"\"\"\n",
    "# from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "from __future__ import unicode_literals\n",
    "\n",
    "from cleverhans.attacks import BasicIterativeMethod\n",
    "from cleverhans.attacks import FastGradientMethod\n",
    "from cleverhans.attacks import DeepFool\n",
    "from cleverhans.loss import CrossEntropy\n",
    "from cleverhans.utils import AccuracyReport\n",
    "# from cleverhans.utils_keras import cnn_model\n",
    "from cleverhans.utils_keras import KerasModelWrapper\n",
    "from keras.datasets import cifar10\n",
    "from cleverhans.utils_tf import train, model_eval\n",
    "import keras\n",
    "from keras import backend\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.platform import flags\n",
    "import os\n",
    "from lenet_model import cifar_model\n",
    "from cleverhans.utils import pair_visual, grid_visual\n",
    "\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '3'\n",
    "\n",
    "FLAGS = flags.FLAGS\n",
    "\n",
    "\n",
    "def mnist_tutorial(train_start=0, train_end=50000, test_start=0,\n",
    "                   test_end=10000, nb_epochs=6, batch_size=128,\n",
    "                   learning_rate=0.001, train_dir=\"train_dir\",\n",
    "                   filename=\"cifar.ckpt\", load_model=False,\n",
    "                   testing=False, label_smoothing=0.1):\n",
    "    \"\"\"\n",
    "    MNIST CleverHans tutorial\n",
    "    :param train_start: index of first training set example\n",
    "    :param train_end: index of last training set example\n",
    "    :param test_start: index of first test set example\n",
    "    :param test_end: index of last test set example\n",
    "    :param nb_epochs: number of epochs to train model\n",
    "    :param batch_size: size of training batches\n",
    "    :param learning_rate: learning rate for training\n",
    "    :param train_dir: Directory storing the saved model\n",
    "    :param filename: Filename to save model under\n",
    "    :param load_model: True for load, False for not load\n",
    "    :param testing: if true, test error is calculated\n",
    "    :param label_smoothing: float, amount of label smoothing for cross entropy\n",
    "    :return: an AccuracyReport object\n",
    "    \"\"\"\n",
    "    keras.layers.core.K.set_learning_phase(0)\n",
    "\n",
    "    # Object used to keep track of (and return) key accuracies\n",
    "    report = AccuracyReport()\n",
    "\n",
    "    # Set TF random seed to improve reproducibility\n",
    "    tf.set_random_seed(1234)\n",
    "    viz_enabled=True\n",
    "    targeted=True\n",
    "    nb_classes=10\n",
    "    \n",
    "\n",
    "    if not hasattr(backend, \"tf\"):\n",
    "        raise RuntimeError(\"This tutorial requires keras to be configured\"\n",
    "                           \" to use the TensorFlow backend.\")\n",
    "\n",
    "    if keras.backend.image_dim_ordering() != 'tf':\n",
    "        keras.backend.set_image_dim_ordering('tf')\n",
    "        print(\"INFO: '~/.keras/keras.json' sets 'image_dim_ordering' to \"\n",
    "              \"'th', temporarily setting to 'tf'\")\n",
    "\n",
    "    # Create TF session and set as Keras backend session\n",
    "    sess = tf.Session()\n",
    "    keras.backend.set_session(sess)\n",
    "\n",
    "    # Get MNIST test data\n",
    "    (x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "    print('x_train shape:', x_train.shape)\n",
    "    print(x_train.shape[0], 'train samples')\n",
    "    print(x_test.shape[0], 'test samples')\n",
    "    num_classes=10\n",
    "    x_train = x_train.astype('float32')\n",
    "    x_test = x_test.astype('float32')\n",
    "    x_train /= 255.\n",
    "    x_test /= 255.\n",
    "    y_train_ori = y_train\n",
    "    y_test_ori = y_test\n",
    "    y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "    y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "    print ('y_train.shape',y_train.shape)\n",
    "\n",
    "    # x_train = np.pad(x_train, ((0, 0), (2, 2), (2, 2), (0, 0)), mode='constant')\n",
    "    # x_test = np.pad(x_test, ((0, 0), (2, 2), (2, 2), (0, 0)), mode='constant')\n",
    "\n",
    "    # Obtain Image Parameters\n",
    "    img_rows, img_cols, nchannels = x_train.shape[1:4]\n",
    "    print('img_rows: {}, img_cols: {}, nchannels: {}'.format(img_rows, img_cols, nchannels))\n",
    "    nb_classes = y_train.shape[1]\n",
    "\n",
    "    if targeted:\n",
    "        if viz_enabled:\n",
    "            # Initialize our array for grid visualization\n",
    "            grid_shape = (nb_classes, nb_classes, img_rows, img_cols, nchannels)\n",
    "            grid_viz_data = np.zeros(grid_shape, dtype='f')\n",
    "            \n",
    "    # Define input TF placeholder\n",
    "    x = tf.placeholder(tf.float32, shape=(None, img_rows, img_cols,\n",
    "                                          nchannels))\n",
    "    y = tf.placeholder(tf.float32, shape=(None, nb_classes))\n",
    "\n",
    "    # Define TF model graph\n",
    "    model = cifar_model(img_rows=img_rows, img_cols=img_cols,\n",
    "                      channels=nchannels, nb_filters=64,\n",
    "                      nb_classes=nb_classes)\n",
    "    preds = model(x)\n",
    "    print(\"Defined TensorFlow model graph.\")\n",
    "\n",
    "    def evaluate():\n",
    "        # Evaluate the accuracy of the MNIST model on legitimate test examples\n",
    "        eval_params = {'batch_size': batch_size}\n",
    "        acc = model_eval(sess, x, y, preds, x_test, y_test, args=eval_params)\n",
    "        report.clean_train_clean_eval = acc\n",
    "#        assert X_test.shape[0] == test_end - test_start, X_test.shape\n",
    "        print('Test accuracy on legitimate examples: %0.4f' % acc)\n",
    "\n",
    "    # Train an MNIST model\n",
    "    train_params = {\n",
    "        'nb_epochs': nb_epochs,\n",
    "        'batch_size': batch_size,\n",
    "        'learning_rate': learning_rate,\n",
    "        'train_dir': train_dir,\n",
    "        'filename': filename\n",
    "    }\n",
    "\n",
    "    rng = np.random.RandomState([2017, 8, 30])\n",
    "    if not os.path.exists(train_dir):\n",
    "        os.mkdir(train_dir)\n",
    "\n",
    "    ckpt = tf.train.get_checkpoint_state(train_dir)\n",
    "    print(train_dir, ckpt)\n",
    "    ckpt_path = False if ckpt is None else ckpt.model_checkpoint_path\n",
    "    wrap = KerasModelWrapper(model)\n",
    "\n",
    "    if load_model and ckpt_path:\n",
    "        saver = tf.train.Saver()\n",
    "        print(ckpt_path)\n",
    "        saver.restore(sess, ckpt_path)\n",
    "        print(\"Model loaded from: {}\".format(ckpt_path))\n",
    "        evaluate()\n",
    "    else:\n",
    "        print(\"Model was not loaded, training from scratch.\")\n",
    "        loss = CrossEntropy(wrap, smoothing=label_smoothing)\n",
    "        train(sess, loss, x, y, x_train, y_train, evaluate=evaluate,\n",
    "              args=train_params, save=True, rng=rng)\n",
    "        print('Training done!')\n",
    "\n",
    "    # Calculate training error\n",
    "    print('testing param:', testing)\n",
    "    if testing:\n",
    "        eval_params = {'batch_size': batch_size}\n",
    "        acc = model_eval(sess, x, y, preds, x_train, y_train, args=eval_params)\n",
    "        report.train_clean_train_clean_eval = acc\n",
    "\n",
    "    # Initialize the Fast Gradient Sign Method (FGSM) attack object and graph\n",
    "    # fgsm = FastGradientMethod(wrap, sess=sess)\n",
    "    method='BIM'\n",
    "    print('method chose: ', method)\n",
    "    clw=BasicIterativeMethod(wrap, sess=sess)\n",
    "    clw_params = {'eps': 0.3,\n",
    "                  'clip_min':0.,\n",
    "                  'clip_max': 1.}\n",
    "    adv_x = clw.generate(x, **clw_params)\n",
    "    with sess.as_default():\n",
    "        feed_dict={x:x_test[:1000], y:y_test[:1000]}\n",
    "        store_data=adv_x.eval(feed_dict=feed_dict)\n",
    "        print('store_data: {}'.format(store_data.shape))\n",
    "        with open('cifar_{}_data.pkl'.format(method),'wb') as fw:\n",
    "            pickle.dump(store_data, fw, protocol=2)\n",
    "            print('data stored!')\n",
    "\n",
    "\n",
    "    # Consider the attack to be constant\n",
    "    adv_x = tf.stop_gradient(adv_x)\n",
    "\n",
    "    preds_adv = model(adv_x)\n",
    "\n",
    "    # Evaluate the accuracy of the MNIST model on adversarial examples\n",
    "    eval_par = {'batch_size': batch_size}\n",
    "    acc = model_eval(sess, x, y, preds_adv, x_test, y_test, args=eval_par)\n",
    "    print('Test accuracy on adversarial examples: %0.4f\\n' % acc)\n",
    "    report.clean_train_adv_eval = acc\n",
    "\n",
    "    # Calculating train error\n",
    "    if testing:\n",
    "        eval_par = {'batch_size': batch_size}\n",
    "        acc = model_eval(sess, x, y, preds_adv, x_train,\n",
    "                         y_train, args=eval_par)\n",
    "        report.train_clean_train_adv_eval = acc\n",
    "\n",
    "    if viz_enabled:\n",
    "        for j in range(nb_classes):\n",
    "            if targeted:\n",
    "                for i in range(nb_classes):\n",
    "                    grid_viz_data[i, j] = adv_x[i * nb_classes + j]\n",
    "        print(grid_viz_data.shape)\n",
    "\n",
    "    if viz_enabled:\n",
    "        import matplotlib.pyplot as plt\n",
    "        _ = grid_visual(grid_viz_data)\n",
    "\n",
    "\n",
    "    return report\n",
    "\n",
    "\n",
    "def main(argv=None):\n",
    "    mnist_tutorial(nb_epochs=FLAGS.nb_epochs,\n",
    "                   batch_size=FLAGS.batch_size,\n",
    "                   learning_rate=FLAGS.learning_rate,\n",
    "                   train_dir=FLAGS.train_dir,\n",
    "                   filename=FLAGS.filename,\n",
    "                   load_model=FLAGS.load_model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (50000, 32, 32, 3)\n",
      "50000 train samples\n",
      "10000 test samples\n",
      "y_train.shape (50000, 10)\n",
      "img_rows: 32, img_cols: 32, nchannels: 3\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'channels' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-2cac723e09a8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDEFINE_string\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'filename'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'cifar.ckpt'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Checkpoint filename.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDEFINE_boolean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'load_model'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Load saved model or train.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/mnt/jiali/anaconda3/lib/python3.6/site-packages/tensorflow/python/platform/app.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(main, argv)\u001b[0m\n\u001b[1;32m    122\u001b[0m   \u001b[0;31m# Call the main function, passing through any arguments\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m   \u001b[0;31m# to the final program.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 124\u001b[0;31m   \u001b[0m_sys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    125\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-1-b92c2d358824>\u001b[0m in \u001b[0;36mmain\u001b[0;34m(argv)\u001b[0m\n\u001b[1;32m    226\u001b[0m                    \u001b[0mtrain_dir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFLAGS\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_dir\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m                    \u001b[0mfilename\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFLAGS\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 228\u001b[0;31m                    load_model=FLAGS.load_model)\n\u001b[0m",
      "\u001b[0;32m<ipython-input-1-b92c2d358824>\u001b[0m in \u001b[0;36mmnist_tutorial\u001b[0;34m(train_start, train_end, test_start, test_end, nb_epochs, batch_size, learning_rate, train_dir, filename, load_model, testing, label_smoothing)\u001b[0m\n\u001b[1;32m    108\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mviz_enabled\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m             \u001b[0;31m# Initialize our array for grid visualization\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 110\u001b[0;31m             \u001b[0mgrid_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnb_classes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnb_classes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg_rows\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg_cols\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchannels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    111\u001b[0m             \u001b[0mgrid_viz_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrid_shape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'f'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'channels' is not defined"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "flags.DEFINE_integer('nb_epochs', 40, 'Number of epochs to train model')\n",
    "flags.DEFINE_integer('batch_size', 128, 'Size of training batches')\n",
    "flags.DEFINE_float('learning_rate', 0.001, 'Learning rate for training')\n",
    "flags.DEFINE_string('train_dir', './cifar_train_dir',\n",
    "                    'Directory where to save model.')\n",
    "flags.DEFINE_string('filename', 'cifar.ckpt', 'Checkpoint filename.')\n",
    "flags.DEFINE_boolean('load_model', True, 'Load saved model or train.')\n",
    "tf.app.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
